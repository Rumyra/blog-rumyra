<p>Welcome to my Codevember. This month Iâ€™m going to take you through some audio visualisation techniques in the browser. Iâ€™ve written and spoken about this a number of times, as well as made a few codepens every now and again, but I thought I would take this month to go over creating audio triggered visuals from the ground up.</p>
<p>Not only do I hope this be a learning journey for you, but one for me as well, thereâ€™s been a number of different techniques, new web features, libraries etcâ€¦ that Iâ€™ve wanted to try, it seems like Codevember is the perfect opportunity.</p>
<p data-height="300" data-theme-id="1345" data-slug-hash="pEMGEP" data-default-tab="js,result" data-user="Rumyra" data-embed-version="2" data-pen-title="Codevember AudioVis #1" class="codepen">See the Pen <a href="https://codepen.io/Rumyra/pen/pEMGEP/">Codevember AudioVis #1</a> by Rumyra (<a href="http://codepen.io/Rumyra">@Rumyra</a>) on <a href="http://codepen.io">CodePen</a>.</p>
<script async src="https://production-assets.codepen.io/assets/embed/ei.js"></script>
<p>Weâ€™re going to start vanilla, from the very basics, just using the very minimal we can from the web audio API and some DOM elements, then slowly Iâ€™ll start trying some different techniques. By the end we would have covered audio analysing, new css techniques, d3.js which I find is so suited to audio-vis, bringing in some svgs and hopefully some canvas too.</p>
<p>READMORE</p>
<p>And along with each technique Iâ€™ll be taking influence from somewhere different, be that an artist, a book from the <a href="https://www.instagram.com/p/BLWXiGdDDmo/?taken-by=rumyra">stepshelf</a> or some tumblr somewhere.</p>
<p>By the end of the month youâ€™ll understand why audio vis has excited me for all these years, and why the browser can be such an incredible environment for this creativity.</p>
<p>A couple of things to note:</p>
<ul>
<li>This is a learning experience for me too, so things may stay quite basic. The code will probably <em>be</em> basic, however this does mean it wonâ€™t be too complicated for entry level coders.</li>
<li>Iâ€™ll be analysing audio from the microphone, which means Iâ€™ll be using the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API">Media Streams API</a>, which only works over https, youâ€™ll need to view the pens over https://codepen.io</li>
<li>Things work best in Canary so Iâ€™ve noticed, please donâ€™t expect pens to work cross browser. The main end game for me is to integrate them into my VJ software, which I run in a sandboxed environment (my machine, my choice of browser) sux I know!</li>
<li>Iâ€™ll be cross posting all these articles to both my <a href="https://codepen.io/Rumyra/posts/published/">Codepen Blog</a> and <a href="http://rumyrashead.com/">my personal blog</a>.</li>
<li>There's a high chance I won't make every single day, but I will try ðŸ™ƒ</li>
</ul>
<h2>So Letâ€™s Begin</h2>
<h3>Basic audio analysis and DOM manipulation</h3>
<p>Letâ€™s start with the audio things weâ€™re going to need. The audio API can be a bit over whelming. Thereâ€™s a whole bunch of properties and methods you get when you create a new audio context. Thereâ€™s inputs, filters, effectsâ€¦ but we can feel a bit better because we only need one piece of functionality - the analyser.</p>
<h4>Setting up the audio API</h4>
<p>Letâ€™s start by creating a new audio context and initiating our variables.</p>
<pre><code class="language-javascript">// set up audio context
var audioContext = (window.AudioContext || window.webkitAudioContext);
// create audio class
if (audioContext) {
  // Web Audio API is available.
  var audioAPI = new audioContext();
  } else {
  // Web Audio API is not available. Ask the user to use a supported browser.
  alert("Oh nos! It appears your browser does not support the Web Audio API, please upgrade or use a different browser");
}

// variables
var analyserNode,
  frequencyData = new Uint8Array(256);
const screen = document.querySelector('#screen'),
  allRepeatedEls = document.querySelectorAll('#screen section'),
  totalEls = allRepeatedEls.length;
</code></pre>
<p>Here weâ€™re checking the browser has the audio API available and instantiating a new context <code>var audioAPI</code> for use.</p>
<p>Then weâ€™re just creating a few variables for use later on.</p>
<p>Now we need to hook into the functionality of the analyser node that comes with the audio API. The analyser node comes with methods for us to access both frequency and time data, for what we want we just need the <code>getByteFrequencyData</code> method which we will use later. But as that uses â€˜fftâ€™ data (fast fourier transform) we need to set up an array for that data to be saved into, and also set the size. This is where the <code>frequencyData = new Uint8Array(256)</code> comes into play above. A good way to view the size is itâ€™s a bit like resolution - the bigger this array, the more intricate the data and thus the more information about the frequencies heard we can display. This is more than likely set to around 1024, however for the purposes of a simple visualisation like this first one Iâ€™m taking you through, 256 more than suffices.</p>
<p>So letâ€™s create and connect our analyser node:</p>
<pre><code class="language-javascript">function createAnalyserNode(audioSource) {
  analyserNode = audioAPI.createAnalyser();
  analyserNode.fftSize = 512;
  audioSource.connect(analyserNode);
}
</code></pre>
<p>Note that the <code>fftSize</code> property has been set to twice the array size we set earlier. The in depth stuff behind fast Fourier transforms are slightly out of the remit of this article, but you can <a href="https://en.wikipedia.org/wiki/Fast_Fourier_transform">read more here</a>.</p>
<p>Another thing to note is we <em>connect</em> the analyser node to the audio source, as all methods within the audio API are are viewed upon as nodes that you connect together. So you can connect inputs to filters to volume nodes to analysers etcâ€¦</p>
<h4>Getting some sound</h4>
<p>Now we want an input for the audio API to analyse, we can just grab the microphone input: (NB this API needs permissions and only works over https or on localhostâ€¦ just change the codepen url to have https:// at the beginning).</p>
<pre><code class="language-javascript">// getUserMedia success callback -> pipe audio stream into audio API
var gotStream = function(stream) {
  // Create an audio input from the stream.
  var audioSource = audioAPI.createMediaStreamSource(stream);
  createAnalyserNode(audioSource);
  animateStuff();
}

navigator.mediaDevices.getUserMedia({ audio: true, video: false })
  .then(gotStream);
</code></pre>
<p>Weâ€™re calling the <code>gotStream</code> function when we receive an audio stream from the microphone, and within that weâ€™re piping it into the audio API and calling the <code>createAnalyserNode</code> function from above.</p>
<p>So the audio API now is analysing the audio stream from the microphone and we can stop here. But, we kinda want to move something around the browser based on the data we receive.</p>
<h4>Animating stuff</h4>
<p>You may have noticed the <code>gotStream</code> function calling <code>animateStuff()</code> which we havenâ€™t written yet. Now hereâ€™s the fun part.</p>
<pre><code class="language-javascript">function animateStuff() {
  requestAnimationFrame(animateStuff);
  analyserNode.getByteFrequencyData(frequencyData);
}
</code></pre>
<p>This is the start of our awesome animating function. We want it to keep running and analysing the sound, so weâ€™ll use <code>requestAnimationFrame</code> for that. Then we call the <code>getByteFrequencyData</code> method on the analyser node we connected earlier and pass in our frequencyData array. This means at every item in our array represents a frequency and when called a volume level is being logged against that frequency.</p>
<p>The volume, (itâ€™s actually amplitude, but, meh words), is just a number and we can use that number to change things, itâ€™s updating all the time because of our <code>requestAnimationFrame</code>.</p>
<p>So to my inspiration for this set. Let me introduce <a href="https://www.artsy.net/artist/bridget-riley">Bridget Riley</a>. I only discovered her this year on a visit to the <a href="https://www.nationalgalleries.org/visit/introduction-118">Scottish Gallery of Modern Art</a> in Edinburgh - such stunning paintings! I knew as soon as I walked into the exhibition I had to make some of them move!</p>
<figure>
  <img src="/media/bridgetBook.jpg" />
  <figcaption>Bridget Rileys Book from the Scottish exhibition</figcaption>
</figure>
<p>So letâ€™s start with 'Rattle'. Itâ€™s a simple one where we can just create some sections and style them with background gradients and then make them shrink and grow horizontally to the sound.</p>
<figure>
  <img src="/media/rattle.jpg" />
  <figcaption>Bridget Riley: Rattle</figcaption>
</figure>
<pre><code class="language-html">&lt;div id="screen">
  &lt;section>&lt;/section>
  &lt;section>&lt;/section>
  &lt;section>&lt;/sect&lt;on>
  &lt;section>&lt;/section>
  &lt;section>&lt;/section>
  &lt;section>&lt;/section>
  &lt;section>&lt;/section>
  &lt;section>&lt;/section>
&lt;/div>
</code></pre>
<pre><code class="language-css">#screen {
  position: relative; padding:1vh;
  width: 100vw; height: 100vh;
  box-sizing: border-box;
  background: black;
}
#screen section {
  height:8vh; margin: 3vh;
  background-color: mediumorchid;
  background-image: linear-gradient(45deg, mediumorchid 9%, seagreen 9%, seagreen 16%, white 16%, white 34%, seagreen 34%, seagreen 41%, mediumorchid 41%, mediumorchid 59%, seagreen 59%, seagreen 66%, white 66%, white 84%, seagreen 84%, seagreen 91%, mediumorchid 91% );
  background-size: 2vh 2vh;
}
#screen section:nth-of-type(2n) {
  background-image: linear-gradient(135deg, indianred 9%, seagreen 9%, seagreen 16%, white 16%, white 34%, seagreen 34%, seagreen 41%, indianred 41%, indianred 59%, seagreen 59%, seagreen 66%, white 66%, white 84%, seagreen 84%, seagreen 91%, indianred 91% );
}
</code></pre>
<p>Now we have 8 sections, all stretched along our <em>screen</em> div. Letâ€™s loop over them and change their width depending on the volume of a frequency.</p>
<p>You may have noticed already we have 256 frequencies and only 8 sections. Thereâ€™s a couple of ways we can <em>play</em> this, (sorry), we can either use the first 8 items in the frequency array for the first section and the next 8 for the next and so on, or we can jump 32 items and get a range of 8 frequencies from our spectrum. The choice is yours really - now itâ€™s just about having fun and playing with the maths. Sometimes it also depends on what music youâ€™re playing.</p>
<p>For simplicity, Iâ€™m going to jump.</p>
<pre><code class="language-javascript">function animateStuff() {
  requestAnimationFrame(animateStuff);
  analyserNode.getByteFrequencyData(frequencyData);
  
  for (let i=0; i&lt;totalEls; i++) {
    var freqVol = frequencyData[i*32]/2;
    allRepeatedEls[i].style.width = freqVol+'vw';
  }
  
}
</code></pre>
<p>The volume values received back from the analyser node range from 0-255, so Iâ€™m dividing by 2 to give rough value for the section to take up.</p>
<p>As the weeks go by weâ€™ll find better, more smoother ways of dealing with the DOM, but for today; huzzah! We made some things move to the music - it plays pretty well to <a href="https://www.youtube.com/watch?v=1plPyJdXKIY">Warrant G and Nate Dog - Regulate</a>, if you were wonderingâ€¦</p>
